{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Загрузка модели Spacy для английского языка\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Удаление знаков препинания\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Приведение текста к нижнему регистру\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def count_word_frequency(tokens):\n",
    "    # Подсчет частоты каждого слова\n",
    "    word_freq = Counter(tokens)\n",
    "    return word_freq\n",
    "\n",
    "\n",
    "def process_file(file_path):\n",
    "    # Чтение файла\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Предобработка текста\n",
    "    processed_text = preprocess_text(text)\n",
    "\n",
    "    # Обработка текста с помощью Spacy и токенизация\n",
    "    doc = nlp(processed_text)\n",
    "    tokens = [token.text for token in doc if not token.is_space]\n",
    "\n",
    "    # Подсчет частоты слов\n",
    "    word_freq = count_word_frequency(tokens)\n",
    "\n",
    "    # Сортировка слов по убыванию частоты\n",
    "    sorted_word_freq = word_freq.most_common()\n",
    "\n",
    "    return sorted_word_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = '../learn_words/subtitles/[English] Jared Kushner_ Israel, Palestine, Hamas, Gaza, Iran, and the Middle East _ Lex Fridman Podcast #399 [DownSub.com].txt'  # Замените на путь к вашему файлу\n",
    "word_freq = process_file(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Структура DataFrame с добавлением столбца 'CommonWord'\n",
    "data = {\n",
    "    \"Word\": [],                  # Слово\n",
    "    \"Frequency\": [],             # Частота встречаемости\n",
    "    \"CommonWord\": [],            # Флаг для обозначения распространенных слов\n",
    "    \"KnowledgeLevel\": [],        # Уровень знания (от 0 до 1)\n",
    "    \"CorrectAnswers\": [],        # Счетчик правильных ответов\n",
    "    \"IncorrectAnswers\": [],      # Счетчик неправильных ответов\n",
    "    \"HintsUsed\": [],             # Счетчик использованных подсказок\n",
    "    \"LastSessionDate\": []        # Дата последней сессии\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Сохранение DataFrame в CSV-файл\n",
    "df.to_csv(\"vocabulary_data.csv\", index=False)\n",
    "print(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backup_data(df, backup_filename):\n",
    "    df.to_csv(backup_filename, index=False)\n",
    "\n",
    "def select_words_for_session(df, n_words=10):\n",
    "    # Сортировка слов по частоте и фильтрация топ-100\n",
    "    top_words = df.sort_values(by='Frequency', ascending=False).head(100)\n",
    "\n",
    "    # Взвешенный выбор слов на основе уровня знания\n",
    "    weights = top_words['KnowledgeLevel'].apply(lambda x: 0.1 if x > 0.9 else (0.2 if x > 0.7 else 1)).tolist()\n",
    "    session_words = top_words.sample(n=n_words, weights=weights)\n",
    "\n",
    "    return session_words\n",
    "\n",
    "def update_knowledge_level(df, word, is_correct_answer):\n",
    "    # Найти строку с соответствующим словом\n",
    "    word_row = df.loc[df['Word'] == word]\n",
    "\n",
    "    # Проверка наличия слова в DataFrame\n",
    "    if word_row.empty:\n",
    "        print(f\"Слово '{word}' не найдено в таблице.\")\n",
    "        return\n",
    "\n",
    "    # Получение текущих значений\n",
    "    current_level = word_row['KnowledgeLevel'].iloc[0]\n",
    "    incorrect_streak = word_row['IncorrectAnswers'].iloc[0]\n",
    "\n",
    "    # Обновление метрики знания\n",
    "    if is_correct_answer:\n",
    "        new_level = min(current_level + 0.1, 1.0)\n",
    "        incorrect_streak = 0\n",
    "    else:\n",
    "        if incorrect_streak == 0:\n",
    "            new_level = max(current_level - 0.1, 0.0)\n",
    "        else:\n",
    "            new_level = max(current_level - 0.3, 0.0)\n",
    "        incorrect_streak += 1\n",
    "\n",
    "    # Обновление данных в DataFrame\n",
    "    df.loc[df['Word'] == word, 'KnowledgeLevel'] = new_level\n",
    "    df.loc[df['Word'] == word, 'IncorrectAnswers'] = incorrect_streak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3852\n"
     ]
    }
   ],
   "source": [
    "print(len(word_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
